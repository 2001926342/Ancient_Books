# Ancient_Books
<div align="center">
  <img src="./assets/logo.png" width="600"/>
  <!-- <a href="https://github.com/Nobody-ML/SoulStar/tree/main/">
    <img src="assets/logo.png" alt="Logo" width="600">  </a> -->
  <h3 align="center">Ancient_Books - å¤ç±è§£è¯»å¤§æ¨¡å‹</h3>
</div>

å¼€æºä¸æ˜“ï¼Œå¦‚æœæœ¬é¡¹ç›®å¸®åˆ°å¤§å®¶ï¼Œå¯ä»¥å³ä¸Šè§’å¸®æˆ‘ç‚¹ä¸ª star~ â­

æ‚¨çš„ star â­æ˜¯æˆ‘ä»¬æœ€å¤§çš„é¼“åŠ±ï¼Œæ¬¢è¿ Starâ­ã€PR å’Œ Issueã€‚

 ## ğŸ“– ç›®å½•
- [Ancient_Books - å¤ç±è§£è¯»å¤§æ¨¡å‹](#Ancient_Books---å¤ç±è§£è¯»å¤§æ¨¡å‹)
  - [ğŸ“– ç›®å½•](#-ç›®å½•)
  - [ğŸ”„ æ¶æ„å›¾](#-æ¶æ„å›¾)
  - [ğŸ“ ç®€ä»‹](#-ç®€ä»‹)
  - [ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•](#ï¸-ä½¿ç”¨æ–¹æ³•)
    - [1.ä¸‹è½½æ¨¡å‹](#1-ä¸‹è½½æ¨¡å‹)
    - [2.ç¯å¢ƒéƒ¨ç½²](#2-ç¯å¢ƒéƒ¨ç½²)
    - [3.æœ¬åœ°éƒ¨ç½²](#3-æœ¬åœ°éƒ¨ç½²)
  - [ğŸ§¾ æ•°æ®æ¥æº](#-æ•°æ®æ¥æº)
  - [ğŸ§‘â€ğŸ’» å¾®è°ƒæŒ‡å—](#-å¾®è°ƒæŒ‡å—)
  - [ğŸ§‘â€ğŸ’» RAGæŒ‡å—](#-RAGæŒ‡å—)
  - [ğŸ§‘â€ğŸ’» LMDeployæ¨¡å‹é‡åŒ–](#-LMDeployæ¨¡å‹é‡åŒ–)
  - [ğŸ“š åº”ç”¨ä½“éªŒ](#-åº”ç”¨ä½“éªŒ)
  - [ğŸ–ï¸ è‡´è°¢](#ï¸-è‡´è°¢)
 
## ğŸ”„ æ¶æ„å›¾


## ğŸ“ ç®€ä»‹

ç”˜è‚ƒæ”¿æ³•å¤§å­¦äººå·¥æ™ºèƒ½å­¦é™¢æ¨å‡ºçš„å¤ç±è§£è¯»å¤§æ¨¡å‹æ˜¯ä¸€æ¬¾è¾…åŠ©å­¦ä¹ çš„å·¥å…·ï¼Œä¸“ä¸ºå¸®åŠ©ç”¨æˆ·ç†è§£å’Œæ¬£èµä¸­å›½å¤ä»£æ–‡å­¦å’Œæ–‡åŒ–è€Œè®¾è®¡ã€‚å®ƒå…·å¤‡å¤è¯—èµæã€æ–‡è¨€æ–‡ç¿»è¯‘ã€æˆè¯­è§£é‡Šã€ã€Šè®ºè¯­ã€‹æ³¨é‡Šä»¥åŠã€Šç™¾å®¶å§“ã€‹è§£è¯»ç­‰åŠŸèƒ½ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿæ·±å…¥é¢†ä¼šå¤ä»£è¯—è¯ã€æ–‡çŒ®ã€æˆè¯­å…¸æ•…å’Œå§“æ°æ–‡åŒ–çš„ç²¾é«“ï¼Œæ˜¯å­¦æœ¯ç ”ç©¶è€…ã€å­¦ç”Ÿä»¥åŠæ‰€æœ‰å¯¹ä¸­å›½å¤ä»£æ–‡åŒ–æ„Ÿå…´è¶£è€…çš„ç†æƒ³åŠ©æ‰‹ã€‚

## ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•

### å¿«é€Ÿå¼€å§‹

1.ä¸‹è½½æ¨¡å‹


å‚è€ƒ [æ¨¡å‹çš„ä¸‹è½½]( https://modelscope.cn/models/CFYuan/Ancient_Books) ã€‚

```bash
pip install modelscope
```

```python
from modelscope import snapshot_download
model_dir = snapshot_download('CFYuan/Ancient_Books')
```


æˆ–è€…å‚è€ƒæ–‡ä»¶ download_model.py ï¼Œæ”¯æŒ7Bæ¨¡å‹ä¸7B int4 é‡åŒ–åçš„æ¨¡å‹

```python
python  download_model.py
python  download_hf.py
```

2.ç¯å¢ƒéƒ¨ç½²

```bash
git clone https://github.com/2001926342/Ancient_Books

pip install requirements.txt
```
3.æœ¬åœ°éƒ¨ç½²

```python
streamlit run web.py --server.port 7860
```


## ğŸ§¾ æ•°æ®æ¥æº

ä»¥ä¸‹æ˜¯é¡¹ç›®ç›®å‰ä½¿ç”¨åˆ°çš„å¼€æºæ•°æ®é›†ï¼Œè¿˜ä½¿ç”¨çˆ¬è™«æŠ€æœ¯è·å–æˆ‘ä»¬æ‰€éœ€æ•°æ®é›†ï¼š

æ–‡è¨€æ–‡ï¼šhttps://huggingface.co/datasets/RUCAIBox/Erya-dataset/tree/main

å¤è¯—ï¼šhttps://github.com/chinese-poetry/chinese-poetry

æ–‡è¨€æ–‡ï¼ˆå¤æ–‡ï¼‰- ç°ä»£æ–‡å¹³è¡Œè¯­æ–™ï¼šhttps://github.com/NiuTrans/Classical-Modern


## ğŸ§‘â€ğŸ’» å¾®è°ƒæŒ‡å—

æœ¬é¡¹ç›®ä½¿ç”¨ xtuner è®­ç»ƒï¼Œåœ¨ internlm2-chat-7b ä¸Šè¿›è¡Œå¾®è°ƒ

1ã€åˆ—å‡ºæ‰€æœ‰å†…ç½®é…ç½®

```bash
xtuner list-cfg
cd /group_share/Ancient_Books/config
xtuner copy-cfg internlm2_chat_7b_qlora_oasst1_e3 .
```

2ã€æ¨¡å‹ä¸‹è½½

```bash
mkdir -p /group_share/Ancient_Books/model
```

```python
import torch
from modelscope import snapshot_download, AutoModel, AutoTokenizer
import os
model_dir = snapshot_download('Shanghai_AI_Laboratory/internlm2-math-7b', cache_dir='/group_share/Ancient_Books/model')
```

3ã€ä¿®æ”¹é…ç½®æ–‡ä»¶

```bash
# ä¿®æ”¹æ¨¡å‹ä¸ºæœ¬åœ°è·¯å¾„
- pretrained_model_name_or_path = 'internlm/internlm-chat-7b'
+ pretrained_model_name_or_path = '/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-7b'

# ä¿®æ”¹è®­ç»ƒæ•°æ®é›†ä¸ºæœ¬åœ°è·¯å¾„
- data_path = 'timdettmers/openassistant-guanaco'
+ data_path = '/group_share/Ancient_Books/dataset/data/sampled_data.json'
```

4ã€å¼€å§‹å¾®è°ƒ

```bash
xtuner train /group_share/Ancient_Books/config/internlm2_chat_7b_qlora_oasst1_e3_copy.py
```
æˆ–è€…ä½¿ç”¨é…ç½®å¥½çš„

```bash
xtuner train /group_share/Ancient_Books/config/internlm2_chat_7b_qlora_ancient_e3.py
```

5ã€PTH æ¨¡å‹è½¬æ¢ä¸º HuggingFace æ¨¡å‹
```bash
mkdir /group_share/Ancient_Books/config/hf
export MKL_SERVICE_FORCE_INTEL=1
export MKL_THREADING_LAYER=GNU
xtuner convert pth_to_hf ./internlm2_chat_7b_qlora_ancient_e3.py \
                         ./work_dirs/internlm2_chat_7b_qlora_ancient_e3/epoch_3.pth \
                         ./hf

```
6ã€HuggingFace æ¨¡å‹åˆå¹¶åˆ°å¤§è¯­è¨€æ¨¡å‹

```bash

# åŸå§‹æ¨¡å‹å‚æ•°å­˜æ”¾çš„ä½ç½®
export NAME_OR_PATH_TO_LLM=/group_share/Ancient_Books/model/Shanghai_AI_Laboratory/internlm2-math-7b
# Hugging Faceæ ¼å¼å‚æ•°å­˜æ”¾çš„ä½ç½®
export NAME_OR_PATH_TO_ADAPTER=/group_share/Ancient_Books/config/hf
# æœ€ç»ˆMergeåçš„å‚æ•°å­˜æ”¾çš„ä½ç½®
mkdir /group_share/Ancient_Books/config/work_dirs/hf_merge
export SAVE_PATH=/group_share/Ancient_Books/config/work_dirs/hf_merge

# æ‰§è¡Œå‚æ•°Merge
xtuner convert merge \
    $NAME_OR_PATH_TO_LLM \
    $NAME_OR_PATH_TO_ADAPTER \
    $SAVE_PATH \
    --max-shard-size 2GB
```

## ğŸ§‘â€ğŸ’» RAGæŒ‡å—

1ã€æ•°æ®é›†æ„å»º
```bash
cd /group_share/Ancient_Books/dataset
python gen_dataset.py
python sample_dataset.py
```

```bash
cd /group_share/Ancient_Books/RAG
python create_db.py
```
2ã€Demo

```python
python web_RAG.py
```

## ğŸ§‘â€ğŸ’»LMDeploy æ¨¡å‹é‡åŒ–

1ã€è¿›è¡Œ 4bit é‡åŒ–

```bash
lmdeploy lite auto_awq \
   /group_share/Ancient_Books/model/Ancient_Books \
  --calib-dataset 'ptb' \
  --calib-samples 128 \
  --calib-seqlen 1024 \
  --w-bits 4 \
  --w-group-size 128 \
  --work-dir /group_share/Ancient_Books/Ancient_Books_int4
```
  
2ã€åŸºäº LMDeploy é«˜æ€§èƒ½éƒ¨ç½²

```python
lmdeploy chat /group_share/Ancient_Books/model/Ancient_Books_int4  --model-name internlm2
```


## ğŸ’• è‡´è°¢

### é¡¹ç›®æˆå‘˜

- é™ˆè¾…å…ƒ-é¡¹ç›®è´Ÿè´£äºº ï¼ˆç”˜è‚ƒæ”¿æ³•å¤§å­¦ Datawhaleé²¸è‹±åŠ©æ•™ è´Ÿè´£æ¨¡å‹å¾®è°ƒè®­ç»ƒï¼Œæ•°æ®æ”¶é›†ï¼ŒRAGå†…å®¹æ•´ç†ï¼‰
- å¼ ä¸–æ–Œ-é¡¹ç›®è´Ÿè´£äºº ï¼ˆç”˜è‚ƒæ”¿æ³•å¤§å­¦ï¼‰
- æŸ´æ‰¿æ¸… ï¼ˆç”˜è‚ƒæ”¿æ³•å¤§å­¦ï¼‰
- ææ™ºæ±Ÿ ï¼ˆç”˜è‚ƒæ”¿æ³•å¤§å­¦ï¼‰
- ç¬¦é“¶éœ ï¼ˆç”˜è‚ƒæ”¿æ³•å¤§å­¦ï¼‰

### ç‰¹åˆ«é¸£è°¢
<div align="center">
 
***æ„Ÿè°¢ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤ç»„ç»‡çš„ ä¹¦ç”ŸÂ·æµ¦è¯­å®æˆ˜è¥ å­¦ä¹ æ´»åŠ¨~***

***æ„Ÿè°¢ OpenXLab å¯¹é¡¹ç›®éƒ¨ç½²çš„ç®—åŠ›æ”¯æŒ~***

***æ„Ÿè°¢ æµ¦è¯­å°åŠ©æ‰‹ å¯¹é¡¹ç›®çš„æ”¯æŒ~***

***æ„Ÿè°¢ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤æ¨å‡ºçš„ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹å®æˆ˜è¥ï¼Œä¸ºæˆ‘ä»¬çš„é¡¹ç›®æä¾›å®è´µçš„æŠ€æœ¯æŒ‡å¯¼å’Œå¼ºå¤§çš„ç®—åŠ›æ”¯æŒï¼***
